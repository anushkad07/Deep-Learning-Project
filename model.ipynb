{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SingleScoreCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleScoreCNN, self).__init__()\n",
    "        # Define the layers of the CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8)  # Adjust the size based on the input size\n",
    "        self.fc2 = nn.Linear(64 * 8, 64 * 2)  \n",
    "        self.fc3 = nn.Linear(64 * 2, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "model = SingleScoreCNN()\n",
    "output = model(torch.randn(1, 3, 64, 64))  # Example input tensor (batch_size, channels, height, width)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.MSELoss()  # For example, if it's a regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 1176, 1170, 110, 867, 1174, 364, 702, 1013, 281, 601, 247, 136, 872, 531, 1024, 500, 1069, 628, 1323, 777, 694, 12, 720, 117, 305, 1177, 39, 1031, 1332, 273, 899, 634, 360, 438, 1077, 737, 1062, 716, 492, 620, 1088, 431, 194, 1201, 1336, 836, 1020, 321, 1305, 465, 457, 445, 80, 138, 2, 866, 886, 891, 997, 1058, 250, 1068, 1128, 839, 534, 411, 953, 1075, 903, 1250, 1317, 506, 389, 549, 838, 1071, 365, 665, 1168, 524, 587, 8, 391, 1211, 1186, 738, 1283, 637, 412, 93, 1275, 1304, 501, 1216, 596, 76, 717, 242, 914, 672, 319, 315, 265, 578, 902, 132, 241, 909, 608, 423, 22, 225, 181, 153, 374, 405, 1303, 1276, 650, 519, 874, 394, 462, 303, 757, 515, 1163, 655, 409, 1106, 1040, 1264, 1067, 856, 489, 351, 257, 640, 144, 57, 662, 1131, 62, 871, 1284, 295, 338, 906, 1225, 567, 83, 956, 1125, 1270, 402, 1079, 279, 204, 193, 629, 823, 612, 484, 522, 7, 232, 1237, 1006, 240, 399, 930, 908, 253, 742, 69, 356, 432, 1219, 262, 599, 920, 699, 1318, 306, 418, 878, 663, 255, 854, 342, 463, 235, 557, 1198, 771, 1003, 1083, 933, 1086, 1160, 114, 883, 1236, 1252, 837, 1035, 581, 1063, 941, 390, 9, 347, 483, 481, 769, 555, 999, 1140, 1122, 796, 1224, 985, 339, 1287, 171, 35, 333, 67, 1246, 910, 1159, 1161, 971, 939, 1117, 1197, 1072, 734, 1103, 429, 712, 290, 245, 436, 881, 34, 116, 425, 921, 1133, 450, 566, 18, 1001, 370, 1113, 1333, 38, 840, 618, 49, 536, 528, 161, 584, 155, 414, 323, 102, 27, 166, 223, 233, 150, 774, 631, 397, 293, 466, 112, 706, 1023, 278, 350, 859, 487, 1097, 256, 698, 922, 215, 605, 850, 1220, 4, 901, 331, 562, 77, 1147, 1085, 916, 1199, 244, 1052, 1156, 68, 495, 1319, 1218, 310, 764, 82, 383, 187, 554, 1221, 51, 846, 983, 752, 13, 825, 514, 940, 1254, 318, 209, 1245, 266, 1124, 1080, 224, 126, 128, 818, 288, 1291, 862, 243, 1279, 795, 503, 904, 719, 995, 79, 85, 53, 785, 1192, 642, 210, 54, 208, 713, 1036, 1248, 852, 635, 184, 476, 1048, 1139, 1033, 961, 168, 482, 458, 313, 1193, 368, 565, 617, 1266, 1308, 203, 337, 1015, 322, 1134, 1188, 1094, 239, 1107, 990, 101, 45, 887, 361, 14, 691, 728, 592, 982, 615, 1162, 815, 841, 309, 797, 353, 1180, 630, 814, 1112, 395, 1203, 1025, 853, 556, 1327, 677, 848, 227, 1166, 1091, 931, 747, 43, 178, 334, 539, 1328, 607, 1171, 1045, 376, 960, 186, 73, 127, 598, 314, 780, 1210, 622, 651, 99, 813, 211, 1165, 884, 649, 1132, 585, 824, 955, 1061, 195, 50, 1288, 929, 28, 806, 264, 258, 579, 260, 855, 972, 297, 413, 517, 1185, 681, 157, 1151, 200, 163, 1240, 148, 1057, 1081, 741, 371, 415, 772, 267, 1153, 199, 1268, 442, 704, 282, 709, 111, 1183, 1205, 604, 525, 1194, 179, 685, 348, 213, 1229, 25, 1306, 1110, 786, 893, 486, 1223, 762, 892, 312, 1181, 721, 1208, 873, 216, 1329, 491, 1032, 222, 1204, 959, 801, 950, 1261, 167, 898, 1251, 212, 1027, 316, 231, 472, 749, 1145, 647, 336, 1324, 378, 1022, 198, 286, 46, 41, 392, 1167, 24, 1335, 488, 547, 48, 367, 1315, 880, 656, 970, 498, 16, 379, 923, 1065, 1178, 832, 324, 230, 1034, 1316, 868, 911, 307, 248, 375, 162, 1028, 520, 1260, 1309, 1044, 141, 543, 1330, 151, 325, 105, 502, 1294, 765, 185, 952, 461, 190, 176, 526, 446, 1076, 218, 710, 84, 246, 1101, 1214, 189, 1016, 344, 1115, 943, 879, 1334, 843, 858, 609, 1175, 537, 1150, 583, 439, 1274, 477, 1301, 913, 1256, 404, 479, 220, 1238, 1004, 433, 1037, 1215, 722, 1050, 377, 1099, 918, 611, 386, 552, 657, 614, 633, 91, 301, 177, 646, 1242, 1014, 1259, 3, 427, 349, 714, 455, 510, 684, 1272, 1030, 1243, 776, 589, 624, 490, 687, 1247, 1141, 641, 58, 1005, 745, 900, 1206, 1321, 302, 1009, 981, 382, 962, 497, 683, 968, 676, 139, 927, 726, 831, 1255, 1066, 861, 731, 917, 403, 44, 475, 1322, 88, 643, 219, 718, 340, 974, 571, 1207, 430, 919, 470, 118, 743, 124, 406, 196, 790, 354, 480, 948, 1049, 951, 912, 270, 1226, 784, 90, 275, 268, 808, 857, 1082, 1046, 289, 214, 888, 103, 1325, 715, 753, 597, 1126, 283, 180, 730, 1307, 573, 453, 1239, 387, 897, 369, 444, 1202, 638, 1196, 469, 320, 137, 1053, 756, 261, 678, 870, 1155, 1154, 113, 992, 1000, 1127, 1142, 864, 1293, 896, 236, 1262, 1054, 949, 464, 905, 60, 416, 660, 20, 259, 740, 781, 291, 674, 561, 15, 478, 1281, 471, 362, 682, 421, 385, 1010, 593, 373, 946, 1011, 74, 1092, 1298, 33, 407, 751, 417, 626, 441, 733, 766, 254, 1187, 81, 226, 603, 1002, 724, 1302, 317, 294, 1314, 1123, 40, 834, 468, 1258, 1118, 269, 352, 661, 393, 538, 440, 600, 1267, 400, 59, 156, 675, 849, 410, 277, 1299, 1290, 56, 1055, 249, 97, 1119, 783, 670, 889, 452, 72, 134, 298, 182, 863, 653, 803, 98, 1012, 207, 890, 202, 1104, 426, 359, 172, 876, 602, 548, 1026, 789, 544, 761, 996, 828, 1017, 654, 1074, 1095, 980, 798, 595, 779, 237, 152, 1056, 396, 533, 636, 984, 947, 935, 183, 558, 131, 588, 788, 586, 188, 621, 1217, 108, 1297, 1047, 686, 123, 19, 963, 523, 1300, 459, 451, 794, 817, 511, 1121, 787, 667, 816, 673, 398, 542, 530, 304, 860, 703, 937, 591, 875, 1312, 420, 437, 1230, 958, 754, 299, 1289, 1253, 327, 725, 11, 833, 513, 976, 851, 744, 845, 1136, 1179, 1157, 572, 711, 1098, 10, 942, 158, 164, 979, 146, 973, 332, 1064, 926, 31, 89, 160, 1164, 1271, 346, 107, 693, 590, 1169, 810, 147, 969, 169, 773, 1331, 37, 192, 154, 1292, 560, 758, 577, 52, 553, 1108, 679, 1135, 847, 727, 170, 574, 448, 300, 680, 1263, 812, 1093, 460, 760, 435, 541, 945, 748, 119, 1313, 1042, 575, 842, 763, 1021, 770, 65, 759, 296, 47, 1008, 830, 644, 473, 485, 6, 17, 988, 106, 443, 877, 882, 516, 623, 1043, 750, 94, 965, 1285, 341, 696, 428, 1172, 1249, 708, 1158, 799, 120, 1116, 135, 372, 1182, 424, 271, 1277, 29, 700, 835, 723, 804, 71, 104, 1233, 521, 130, 345, 272, 957, 1078, 419, 827, 274, 234, 800, 986, 280, 75, 326, 938, 895, 1084, 1041, 580, 924, 1235, 639, 129, 508, 1244, 529, 532, 616, 87, 594, 1184, 292, 1278, 363, 1051, 966, 1073, 1190, 1269, 746, 632, 535, 328, 729, 1280, 844, 1213, 627, 1146, 78, 1109, 1228, 1265, 1138, 793, 989, 206, 381, 504, 894, 610, 173, 197, 669, 582, 907, 95, 1102, 63, 512, 1038, 782, 998, 689, 434, 335, 569, 221, 401, 5, 330, 1191, 499, 1212, 551, 1311, 936, 343, 308, 100, 142, 563, 1059, 474, 422, 276, 568, 991, 61, 311, 496, 819, 122, 109, 55, 121, 1148, 285, 978, 175, 1227, 174, 1310, 1257, 932, 688, 1120, 1173, 145, 42, 915, 505, 1326, 251, 820, 358, 1029, 993, 707, 755, 671, 692, 1129, 36, 967, 92, 1019, 1111, 143, 30, 26, 1007, 645, 1089, 238, 652, 664, 735, 1152, 559, 125, 1, 666, 70, 284, 954, 546, 1087, 934, 1320, 576, 540, 1018, 263, 1231, 1137, 739, 805, 191, 791, 1209, 494, 977, 925, 1200, 809, 509, 697, 1286, 32, 1234, 1296, 447, 201, 658, 619, 1143, 1096, 821, 767, 648, 736, 252, 975, 165, 384, 811, 885, 613, 366, 23, 865, 1232, 606, 1195, 329, 668, 456, 690, 205, 380, 768, 732, 1222, 357, 775, 96, 408, 64, 1241, 149, 217, 659, 229, 287, 454, 826, 550, 159, 1090, 1039, 467, 705, 564, 518, 66, 140, 115, 1130, 133, 1144, 545, 695, 1105, 964, 449, 625, 807, 987, 928, 1070, 388, 1100, 228, 493, 1060, 701, 944, 792, 994, 21, 1273, 1149, 1189, 86, 355, 869, 507, 778, 1114, 570, 802, 0, 1295, 527, 1282, 829]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MeasuresDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None, indices=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        if indices is not None:\n",
    "            self.data = data.iloc[indices]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        page = str(int(self.data.iloc[idx]['Page']))\n",
    "        label = self.data.iloc[idx]['Final Score']\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, f\"{page}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to the size expected by the network\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform)\n",
    "\n",
    "# Splitting data indices for train and test\n",
    "total_size = len(dataset)\n",
    "testsizepercent = 0.2\n",
    "test_size = int(testsizepercent * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "train_indices = indices[test_size:]\n",
    "test_indices = indices[:test_size]\n",
    "\n",
    "train_dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform, indices=train_indices)\n",
    "test_dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform, indices=test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], MSE Loss: 0.0756\n",
      "Epoch [2/20], MSE Loss: 0.0183\n",
      "Epoch [3/20], MSE Loss: 0.0142\n",
      "Epoch [4/20], MSE Loss: 0.0141\n",
      "Epoch [5/20], MSE Loss: 0.0147\n",
      "Epoch [6/20], MSE Loss: 0.0152\n",
      "Epoch [7/20], MSE Loss: 0.0140\n",
      "Epoch [8/20], MSE Loss: 0.0132\n",
      "Epoch [9/20], MSE Loss: 0.0127\n",
      "Epoch [10/20], MSE Loss: 0.0128\n",
      "Epoch [11/20], MSE Loss: 0.0149\n",
      "Epoch [12/20], MSE Loss: 0.0141\n",
      "Epoch [13/20], MSE Loss: 0.0172\n",
      "Epoch [14/20], MSE Loss: 0.0163\n",
      "Epoch [15/20], MSE Loss: 0.0123\n",
      "Epoch [16/20], MSE Loss: 0.0134\n",
      "Epoch [17/20], MSE Loss: 0.0139\n",
      "Epoch [18/20], MSE Loss: 0.0111\n",
      "Epoch [19/20], MSE Loss: 0.0103\n",
      "Epoch [20/20], MSE Loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Prepare model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        # Move data to GPU if available\n",
    "        # images, labels = images.cuda(), labels.cuda() if torch.cuda.is_available() else (images, labels)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], MSE Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleScoreCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
