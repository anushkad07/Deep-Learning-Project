{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SingleScoreCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleScoreCNN, self).__init__()\n",
    "        # Define the layers of the CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8)  # Adjust the size based on the input size\n",
    "        self.fc2 = nn.Linear(64 * 8, 64 * 2)  \n",
    "        self.fc3 = nn.Linear(64 * 2, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "model = SingleScoreCNN()\n",
    "output = model(torch.randn(1, 3, 64, 64))  # Example input tensor (batch_size, channels, height, width)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.MSELoss()  # For example, if it's a regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Applications/Anaconda/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9096C4C6-0664-3775-B06F-54E79C6B0E3F> /Applications/Anaconda/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /Applications/Anaconda/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MeasuresDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None, indices=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        if indices is not None:\n",
    "            self.data = data.iloc[indices]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        page = str(int(self.data.iloc[idx]['Page']))\n",
    "        label = self.data.iloc[idx]['Final Score']\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, f\"{page}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to the size expected by the network\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform)\n",
    "\n",
    "# Splitting data indices for train and test\n",
    "total_size = len(dataset)\n",
    "testsizepercent = 0.2\n",
    "test_size = int(testsizepercent * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "train_indices = indices[test_size:]\n",
    "test_indices = indices[:test_size]\n",
    "\n",
    "train_dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform, indices=train_indices)\n",
    "test_dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform, indices=test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], MSE Loss: 0.0194\n",
      "Epoch [2/20], MSE Loss: 0.0142\n",
      "Epoch [3/20], MSE Loss: 0.0134\n",
      "Epoch [4/20], MSE Loss: 0.0125\n",
      "Epoch [5/20], MSE Loss: 0.0117\n",
      "Epoch [6/20], MSE Loss: 0.0114\n",
      "Epoch [7/20], MSE Loss: 0.0110\n",
      "Epoch [8/20], MSE Loss: 0.0106\n",
      "Epoch [9/20], MSE Loss: 0.0113\n",
      "Epoch [10/20], MSE Loss: 0.0106\n",
      "Epoch [11/20], MSE Loss: 0.0102\n",
      "Epoch [12/20], MSE Loss: 0.0090\n",
      "Epoch [13/20], MSE Loss: 0.0091\n",
      "Epoch [14/20], MSE Loss: 0.0075\n",
      "Epoch [15/20], MSE Loss: 0.0064\n",
      "Epoch [16/20], MSE Loss: 0.0058\n",
      "Epoch [17/20], MSE Loss: 0.0056\n",
      "Epoch [18/20], MSE Loss: 0.0054\n",
      "Epoch [19/20], MSE Loss: 0.0045\n",
      "Epoch [20/20], MSE Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Prepare model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 20\n",
    "device = \"mps\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        # Move data to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], MSE Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleScoreCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.6, 0.8, 1]\n",
    "def model_predict_class(image, model):\n",
    "    scores = model(image)\n",
    "    scores = scores.squeeze()\n",
    "    print(scores)\n",
    "    categories = []\n",
    "    for score in scores:\n",
    "        if score <= thresholds[0]:\n",
    "            category = \"Very Poor\"\n",
    "        elif thresholds[0] < score <= thresholds[1]:\n",
    "            category = \"Poor\"\n",
    "        elif thresholds[1] < score <= thresholds[2]:\n",
    "            category = \"Fair\"\n",
    "        elif thresholds[2] < score <= thresholds[3]:\n",
    "            category = \"Good\"\n",
    "        else:\n",
    "            category = \"Very Good\"\n",
    "        categories.append(category)    \n",
    "    return categories     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0045, -0.0032, -0.0031, -0.0037, -0.0044, -0.0048, -0.0036, -0.0048,\n",
      "        -0.0047, -0.0021, -0.0046, -0.0049, -0.0032, -0.0042, -0.0046, -0.0026,\n",
      "        -0.0036, -0.0041, -0.0034, -0.0040, -0.0050, -0.0041, -0.0043, -0.0032,\n",
      "        -0.0041, -0.0043, -0.0030, -0.0045, -0.0033, -0.0037, -0.0044, -0.0046],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/44306.jpg: Very Poor (Label: 0.3367826044559479)\n",
      "./combined/59888.jpg: Very Poor (Label: 0.37280356884002686)\n",
      "./combined/8478.jpg: Very Poor (Label: 0.3767063617706299)\n",
      "./combined/14518.jpg: Very Poor (Label: 0.37935277819633484)\n",
      "./combined/38861.jpg: Very Poor (Label: 0.27792832255363464)\n",
      "./combined/3721.jpg: Very Poor (Label: 0.428117573261261)\n",
      "./combined/69497.jpg: Very Poor (Label: 0.47927504777908325)\n",
      "./combined/49164.jpg: Very Poor (Label: 0.3618248999118805)\n",
      "./combined/33684.jpg: Very Poor (Label: 0.33088418841362)\n",
      "./combined/28162.jpg: Very Poor (Label: 0.41489821672439575)\n",
      "./combined/12970.jpg: Very Poor (Label: 0.4822719693183899)\n",
      "./combined/63425.jpg: Very Poor (Label: 0.353488028049469)\n",
      "./combined/7627.jpg: Very Poor (Label: 0.5463676452636719)\n",
      "./combined/55517.jpg: Very Poor (Label: 0.3409286439418793)\n",
      "./combined/55147.jpg: Very Poor (Label: 0.36583665013313293)\n",
      "./combined/48775.jpg: Very Poor (Label: 0.25704464316368103)\n",
      "./combined/40345.jpg: Very Poor (Label: 0.4429296553134918)\n",
      "./combined/8182.jpg: Very Poor (Label: 0.42574334144592285)\n",
      "./combined/30047.jpg: Very Poor (Label: 0.46881937980651855)\n",
      "./combined/45844.jpg: Very Poor (Label: 0.4149131178855896)\n",
      "./combined/66277.jpg: Very Poor (Label: 0.25528356432914734)\n",
      "./combined/39636.jpg: Very Poor (Label: 0.2961859107017517)\n",
      "./combined/35615.jpg: Very Poor (Label: 0.5123087763786316)\n",
      "./combined/49922.jpg: Very Poor (Label: 0.20880739390850067)\n",
      "./combined/38532.jpg: Very Poor (Label: 0.49811384081840515)\n",
      "./combined/36486.jpg: Very Poor (Label: 0.26150739192962646)\n",
      "./combined/63075.jpg: Very Poor (Label: 0.5688021779060364)\n",
      "./combined/28532.jpg: Very Poor (Label: 0.2036718875169754)\n",
      "./combined/43093.jpg: Very Poor (Label: 0.2917836308479309)\n",
      "./combined/16460.jpg: Very Poor (Label: 0.8050859570503235)\n",
      "./combined/27278.jpg: Very Poor (Label: 0.5117610692977905)\n",
      "./combined/37278.jpg: Very Poor (Label: 0.5703657865524292)\n",
      "tensor([-0.0036, -0.0043, -0.0043, -0.0046, -0.0042, -0.0037, -0.0047, -0.0053,\n",
      "        -0.0029, -0.0043, -0.0050, -0.0027, -0.0043, -0.0042, -0.0049, -0.0038,\n",
      "        -0.0034, -0.0042, -0.0051, -0.0042, -0.0049, -0.0039, -0.0035, -0.0041,\n",
      "        -0.0045, -0.0044, -0.0038, -0.0042, -0.0033, -0.0038, -0.0035, -0.0051],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/39323.jpg: Very Poor (Label: 0.45409321784973145)\n",
      "./combined/67173.jpg: Very Poor (Label: 0.44903764128685)\n",
      "./combined/54613.jpg: Very Poor (Label: 0.3809809386730194)\n",
      "./combined/2833.jpg: Very Poor (Label: 0.33796799182891846)\n",
      "./combined/7762.jpg: Very Poor (Label: 0.47528767585754395)\n",
      "./combined/31343.jpg: Very Poor (Label: 0.35365062952041626)\n",
      "./combined/3664.jpg: Very Poor (Label: 0.3258098065853119)\n",
      "./combined/396.jpg: Very Poor (Label: 0.4373660087585449)\n",
      "./combined/44756.jpg: Very Poor (Label: 0.46571582555770874)\n",
      "./combined/2999.jpg: Very Poor (Label: 0.4621296525001526)\n",
      "./combined/59534.jpg: Very Poor (Label: 0.3698391616344452)\n",
      "./combined/51104.jpg: Very Poor (Label: 0.5346242785453796)\n",
      "./combined/39266.jpg: Very Poor (Label: 0.9663807153701782)\n",
      "./combined/52728.jpg: Very Poor (Label: 0.3075033724308014)\n",
      "./combined/30552.jpg: Very Poor (Label: 0.4893557131290436)\n",
      "./combined/59021.jpg: Very Poor (Label: 0.3353128731250763)\n",
      "./combined/68286.jpg: Very Poor (Label: 0.35593438148498535)\n",
      "./combined/56784.jpg: Very Poor (Label: 0.6516651511192322)\n",
      "./combined/43586.jpg: Very Poor (Label: 0.512844443321228)\n",
      "./combined/15759.jpg: Very Poor (Label: 0.3679032623767853)\n",
      "./combined/26890.jpg: Very Poor (Label: 0.36296582221984863)\n",
      "./combined/38924.jpg: Very Poor (Label: 0.3410586416721344)\n",
      "./combined/47879.jpg: Very Poor (Label: 0.44660162925720215)\n",
      "./combined/44243.jpg: Very Poor (Label: 0.4100388288497925)\n",
      "./combined/7298.jpg: Very Poor (Label: 0.3645436763763428)\n",
      "./combined/41807.jpg: Very Poor (Label: 0.26141196489334106)\n",
      "./combined/24511.jpg: Very Poor (Label: 0.21968090534210205)\n",
      "./combined/70659.jpg: Very Poor (Label: 0.5510207414627075)\n",
      "./combined/20047.jpg: Very Poor (Label: 0.24650150537490845)\n",
      "./combined/66762.jpg: Very Poor (Label: 0.3984478712081909)\n",
      "./combined/6036.jpg: Very Poor (Label: 0.2509579360485077)\n",
      "./combined/18868.jpg: Very Poor (Label: 0.48394104838371277)\n",
      "tensor([-0.0025, -0.0042, -0.0034, -0.0031, -0.0028, -0.0038, -0.0031, -0.0043,\n",
      "        -0.0046, -0.0043, -0.0041, -0.0037, -0.0034, -0.0050, -0.0032, -0.0044,\n",
      "        -0.0045, -0.0043, -0.0047, -0.0028, -0.0049, -0.0046, -0.0036, -0.0032,\n",
      "        -0.0036, -0.0046, -0.0044, -0.0032, -0.0044, -0.0036, -0.0040, -0.0041],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/8028.jpg: Very Poor (Label: 0.9633057713508606)\n",
      "./combined/34842.jpg: Very Poor (Label: 0.5367657542228699)\n",
      "./combined/22095.jpg: Very Poor (Label: 0.40861770510673523)\n",
      "./combined/2130.jpg: Very Poor (Label: 0.3105515241622925)\n",
      "./combined/28477.jpg: Very Poor (Label: 0.43710628151893616)\n",
      "./combined/6935.jpg: Very Poor (Label: 0.4186430871486664)\n",
      "./combined/683.jpg: Very Poor (Label: 0.36927473545074463)\n",
      "./combined/55452.jpg: Very Poor (Label: 0.46879327297210693)\n",
      "./combined/62371.jpg: Very Poor (Label: 0.2946683168411255)\n",
      "./combined/57195.jpg: Very Poor (Label: 0.42680710554122925)\n",
      "./combined/39289.jpg: Very Poor (Label: 0.39807742834091187)\n",
      "./combined/54306.jpg: Very Poor (Label: 0.3916988968849182)\n",
      "./combined/46784.jpg: Very Poor (Label: 0.2843741774559021)\n",
      "./combined/63999.jpg: Very Poor (Label: 0.5053449273109436)\n",
      "./combined/21343.jpg: Very Poor (Label: 0.419516921043396)\n",
      "./combined/6870.jpg: Very Poor (Label: 0.25061851739883423)\n",
      "./combined/55002.jpg: Very Poor (Label: 0.2905755043029785)\n",
      "./combined/61048.jpg: Very Poor (Label: 0.30962228775024414)\n",
      "./combined/67466.jpg: Very Poor (Label: 0.4444652199745178)\n",
      "./combined/48630.jpg: Very Poor (Label: 0.37909746170043945)\n",
      "./combined/36193.jpg: Very Poor (Label: 0.22989776730537415)\n",
      "./combined/24141.jpg: Very Poor (Label: 0.3105893135070801)\n",
      "./combined/13398.jpg: Very Poor (Label: 0.31311550736427307)\n",
      "./combined/51041.jpg: Very Poor (Label: 0.5281466245651245)\n",
      "./combined/16876.jpg: Very Poor (Label: 0.3944268524646759)\n",
      "./combined/32095.jpg: Very Poor (Label: 0.33085504174232483)\n",
      "./combined/20801.jpg: Very Poor (Label: 0.43390798568725586)\n",
      "./combined/27782.jpg: Very Poor (Label: 0.42889007925987244)\n",
      "./combined/14148.jpg: Very Poor (Label: 0.5584520101547241)\n",
      "./combined/6489.jpg: Very Poor (Label: 0.3584165871143341)\n",
      "./combined/63130.jpg: Very Poor (Label: 0.4186748266220093)\n",
      "./combined/7332.jpg: Very Poor (Label: 0.5334049463272095)\n",
      "tensor([-0.0032, -0.0047, -0.0049, -0.0027, -0.0052, -0.0031, -0.0046, -0.0042,\n",
      "        -0.0031, -0.0046, -0.0052, -0.0016, -0.0040, -0.0043, -0.0047, -0.0036,\n",
      "        -0.0046, -0.0044, -0.0050, -0.0028, -0.0027, -0.0036, -0.0041, -0.0039,\n",
      "        -0.0039, -0.0035, -0.0048, -0.0048, -0.0042, -0.0043, -0.0033, -0.0037],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/43139.jpg: Very Poor (Label: 0.2146521955728531)\n",
      "./combined/53139.jpg: Very Poor (Label: 0.3236065208911896)\n",
      "./combined/34004.jpg: Very Poor (Label: 0.4421515166759491)\n",
      "./combined/60659.jpg: Very Poor (Label: 0.5829766392707825)\n",
      "./combined/2560.jpg: Very Poor (Label: 0.4935661554336548)\n",
      "./combined/379.jpg: Very Poor (Label: 0.327903687953949)\n",
      "./combined/22580.jpg: Very Poor (Label: 0.39727693796157837)\n",
      "./combined/36469.jpg: Very Poor (Label: 0.3276568353176117)\n",
      "./combined/17271.jpg: Very Poor (Label: 0.41383883357048035)\n",
      "./combined/3371.jpg: Very Poor (Label: 0.4156336188316345)\n",
      "./combined/41041.jpg: Very Poor (Label: 0.5813817381858826)\n",
      "./combined/57480.jpg: Very Poor (Label: 0.45537540316581726)\n",
      "./combined/40715.jpg: Very Poor (Label: 0.46524909138679504)\n",
      "./combined/34907.jpg: Very Poor (Label: 0.360077828168869)\n",
      "./combined/41411.jpg: Very Poor (Label: 0.26348698139190674)\n",
      "./combined/1659.jpg: Very Poor (Label: 0.3446696400642395)\n",
      "./combined/47896.jpg: Very Poor (Label: 0.4865572154521942)\n",
      "./combined/12423.jpg: Very Poor (Label: 0.5169666409492493)\n",
      "./combined/52378.jpg: Very Poor (Label: 0.8386437296867371)\n",
      "./combined/22979.jpg: Very Poor (Label: 0.2504081130027771)\n",
      "./combined/26193.jpg: Very Poor (Label: 0.2954588234424591)\n",
      "./combined/29289.jpg: Very Poor (Label: 0.4669857323169708)\n",
      "./combined/28027.jpg: Very Poor (Label: 0.377508282661438)\n",
      "./combined/32979.jpg: Very Poor (Label: 0.34706804156303406)\n",
      "./combined/69182.jpg: Very Poor (Label: 0.6017211079597473)\n",
      "./combined/16525.jpg: Very Poor (Label: 0.45525285601615906)\n",
      "./combined/67036.jpg: Very Poor (Label: 0.4256013035774231)\n",
      "./combined/7277.jpg: Very Poor (Label: 0.38726162910461426)\n",
      "./combined/67523.jpg: Very Poor (Label: 0.32912084460258484)\n",
      "./combined/20944.jpg: Very Poor (Label: 0.370860755443573)\n",
      "./combined/18184.jpg: Very Poor (Label: 0.4172925651073456)\n",
      "./combined/28861.jpg: Very Poor (Label: 0.49558672308921814)\n",
      "tensor([-0.0036, -0.0038, -0.0051, -0.0047, -0.0031, -0.0043, -0.0035, -0.0052,\n",
      "        -0.0044, -0.0032, -0.0032, -0.0049, -0.0047, -0.0031, -0.0044, -0.0048,\n",
      "        -0.0043, -0.0031, -0.0047, -0.0046, -0.0041, -0.0034, -0.0050, -0.0048,\n",
      "        -0.0039, -0.0041, -0.0032, -0.0044, -0.0047, -0.0039, -0.0035, -0.0046],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/20552.jpg: Very Poor (Label: 0.4411317706108093)\n",
      "./combined/4908.jpg: Very Poor (Label: 0.3464964032173157)\n",
      "./combined/71048.jpg: Very Poor (Label: 0.4083098769187927)\n",
      "./combined/40650.jpg: Very Poor (Label: 0.5761892795562744)\n",
      "./combined/54756.jpg: Very Poor (Label: 0.3390553295612335)\n",
      "./combined/45517.jpg: Very Poor (Label: 0.6205604076385498)\n",
      "./combined/9269.jpg: Very Poor (Label: 0.48466387391090393)\n",
      "./combined/51942.jpg: Very Poor (Label: 0.40112438797950745)\n",
      "./combined/15309.jpg: Very Poor (Label: 0.23540830612182617)\n",
      "./combined/33391.jpg: Very Poor (Label: 0.4310688078403473)\n",
      "./combined/41104.jpg: Very Poor (Label: 0.4479947090148926)\n",
      "./combined/20102.jpg: Very Poor (Label: 0.3419339060783386)\n",
      "./combined/53093.jpg: Very Poor (Label: 0.3758493959903717)\n",
      "./combined/6173.jpg: Very Poor (Label: 0.19082416594028473)\n",
      "./combined/51554.jpg: Very Poor (Label: 0.5035727024078369)\n",
      "./combined/49534.jpg: Very Poor (Label: 0.4235350489616394)\n",
      "./combined/24907.jpg: Very Poor (Label: 0.41782814264297485)\n",
      "./combined/26039.jpg: Very Poor (Label: 0.5631558299064636)\n",
      "./combined/12136.jpg: Very Poor (Label: 0.33512189984321594)\n",
      "./combined/42397.jpg: Very Poor (Label: 0.3718714714050293)\n",
      "./combined/66627.jpg: Very Poor (Label: 0.43304282426834106)\n",
      "./combined/40200.jpg: Very Poor (Label: 0.38450074195861816)\n",
      "./combined/50345.jpg: Very Poor (Label: 0.30090901255607605)\n",
      "./combined/53569.jpg: Very Poor (Label: 0.5378979444503784)\n",
      "./combined/49867.jpg: Very Poor (Label: 0.2963269054889679)\n",
      "./combined/36039.jpg: Very Poor (Label: 0.29003477096557617)\n",
      "./combined/24842.jpg: Very Poor (Label: 0.6243467926979065)\n",
      "./combined/66332.jpg: Very Poor (Label: 0.469314306974411)\n",
      "./combined/50200.jpg: Very Poor (Label: 0.42420998215675354)\n",
      "./combined/68793.jpg: Very Poor (Label: 0.5135580897331238)\n",
      "./combined/6523.jpg: Very Poor (Label: 0.25869226455688477)\n",
      "./combined/62234.jpg: Very Poor (Label: 0.40285369753837585)\n",
      "tensor([-0.0035, -0.0049, -0.0042, -0.0048, -0.0042, -0.0045, -0.0036, -0.0029,\n",
      "        -0.0056, -0.0045, -0.0047, -0.0036, -0.0031, -0.0030, -0.0043, -0.0043,\n",
      "        -0.0036, -0.0046, -0.0042, -0.0030, -0.0046, -0.0049, -0.0033, -0.0045,\n",
      "        -0.0034, -0.0049, -0.0041, -0.0052, -0.0050, -0.0034, -0.0036, -0.0032],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/54243.jpg: Very Poor (Label: 0.26034247875213623)\n",
      "./combined/29773.jpg: Very Poor (Label: 0.509272038936615)\n",
      "./combined/39773.jpg: Very Poor (Label: 0.37263429164886475)\n",
      "./combined/48325.jpg: Very Poor (Label: 0.4072374999523163)\n",
      "./combined/37628.jpg: Very Poor (Label: 0.38117557764053345)\n",
      "./combined/34511.jpg: Very Poor (Label: 0.6044862270355225)\n",
      "./combined/25615.jpg: Very Poor (Label: 0.35217466950416565)\n",
      "./combined/16175.jpg: Very Poor (Label: 0.2640734314918518)\n",
      "./combined/29636.jpg: Very Poor (Label: 0.5110117793083191)\n",
      "./combined/60209.jpg: Very Poor (Label: 0.43110188841819763)\n",
      "./combined/13232.jpg: Very Poor (Label: 0.3002925515174866)\n",
      "./combined/63560.jpg: Very Poor (Label: 0.1651800572872162)\n",
      "./combined/58775.jpg: Very Poor (Label: 0.6192781329154968)\n",
      "./combined/58260.jpg: Very Poor (Label: 0.6077501177787781)\n",
      "./combined/13662.jpg: Very Poor (Label: 0.37256836891174316)\n",
      "./combined/30417.jpg: Very Poor (Label: 0.3350168466567993)\n",
      "./combined/17764.jpg: Very Poor (Label: 0.22572214901447296)\n",
      "./combined/49888.jpg: Very Poor (Label: 0.37349289655685425)\n",
      "./combined/37297.jpg: Very Poor (Label: 0.3288934528827667)\n",
      "./combined/1209.jpg: Very Poor (Label: 0.2993620038032532)\n",
      "./combined/32996.jpg: Very Poor (Label: 0.36430904269218445)\n",
      "./combined/35245.jpg: Very Poor (Label: 0.3996664583683014)\n",
      "./combined/41554.jpg: Very Poor (Label: 0.29236501455307007)\n",
      "./combined/9286.jpg: Very Poor (Label: 0.52044677734375)\n",
      "./combined/69028.jpg: Very Poor (Label: 0.23834392428398132)\n",
      "./combined/34141.jpg: Very Poor (Label: 0.607175350189209)\n",
      "./combined/57896.jpg: Very Poor (Label: 0.47526833415031433)\n",
      "./combined/13727.jpg: Very Poor (Label: 0.5058339238166809)\n",
      "./combined/50650.jpg: Very Poor (Label: 0.4494112432003021)\n",
      "./combined/9793.jpg: Very Poor (Label: 0.38348791003227234)\n",
      "./combined/19795.jpg: Very Poor (Label: 0.39163902401924133)\n",
      "./combined/30944.jpg: Very Poor (Label: 0.49458396434783936)\n",
      "tensor([-0.0045, -0.0037, -0.0028, -0.0038, -0.0045, -0.0031, -0.0028, -0.0027,\n",
      "        -0.0040, -0.0026, -0.0030, -0.0039, -0.0038, -0.0040, -0.0039, -0.0034,\n",
      "        -0.0040, -0.0031, -0.0048, -0.0034, -0.0041, -0.0040, -0.0046, -0.0043,\n",
      "        -0.0042, -0.0020, -0.0051, -0.0042, -0.0042, -0.0050, -0.0048, -0.0042],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward0>)\n",
      "./combined/25750.jpg: Very Poor (Label: 0.3493332862854004)\n",
      "./combined/28924.jpg: Very Poor (Label: 0.6073712110519409)\n",
      "./combined/6466.jpg: Very Poor (Label: 0.32338544726371765)\n",
      "./combined/18887.jpg: Very Poor (Label: 0.27527284622192383)\n",
      "./combined/29266.jpg: Very Poor (Label: 0.4741353690624237)\n",
      "./combined/55901.jpg: Very Poor (Label: 0.32720017433166504)\n",
      "./combined/25300.jpg: Very Poor (Label: 0.26404449343681335)\n",
      "./combined/71418.jpg: Very Poor (Label: 0.2375715672969818)\n",
      "./combined/51411.jpg: Very Poor (Label: 0.28215092420578003)\n",
      "./combined/8881.jpg: Very Poor (Label: 0.4220219552516937)\n",
      "./combined/62664.jpg: Very Poor (Label: 0.41546350717544556)\n",
      "./combined/59471.jpg: Very Poor (Label: 0.3103591203689575)\n",
      "./combined/21656.jpg: Very Poor (Label: 0.569007158279419)\n",
      "./combined/69478.jpg: Very Poor (Label: 0.40320464968681335)\n",
      "./combined/30102.jpg: Very Poor (Label: 0.3468853533267975)\n",
      "./combined/38162.jpg: Very Poor (Label: 0.4492754638195038)\n",
      "./combined/31206.jpg: Very Poor (Label: 0.4973643720149994)\n",
      "./combined/45901.jpg: Very Poor (Label: 0.39150312542915344)\n",
      "./combined/16899.jpg: Very Poor (Label: 0.28877460956573486)\n",
      "./combined/56291.jpg: Very Poor (Label: 0.4747390151023865)\n",
      "./combined/63833.jpg: Very Poor (Label: 0.3038257360458374)\n",
      "./combined/48260.jpg: Very Poor (Label: 0.2774679362773895)\n",
      "./combined/31713.jpg: Very Poor (Label: 0.6047031879425049)\n",
      "./combined/46291.jpg: Very Poor (Label: 0.29815101623535156)\n",
      "./combined/26486.jpg: Very Poor (Label: 0.4913545548915863)\n",
      "./combined/59867.jpg: Very Poor (Label: 0.4395882189273834)\n",
      "./combined/12073.jpg: Very Poor (Label: 0.419264554977417)\n",
      "./combined/66298.jpg: Very Poor (Label: 0.3064066767692566)\n",
      "./combined/16030.jpg: Very Poor (Label: 0.3305939733982086)\n",
      "./combined/62721.jpg: Very Poor (Label: 0.7032966017723083)\n",
      "./combined/68639.jpg: Very Poor (Label: 0.5085046887397766)\n",
      "./combined/29323.jpg: Very Poor (Label: 0.4657059907913208)\n",
      "tensor([-0.0035, -0.0045, -0.0042, -0.0041, -0.0056, -0.0041, -0.0039, -0.0035,\n",
      "        -0.0035, -0.0030, -0.0028, -0.0031, -0.0032, -0.0042, -0.0048, -0.0050,\n",
      "        -0.0048, -0.0045, -0.0050, -0.0049, -0.0029, -0.0031, -0.0033, -0.0036,\n",
      "        -0.0031, -0.0034, -0.0023, -0.0040], device='mps:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "./combined/32580.jpg: Very Poor (Label: 0.3903859555721283)\n",
      "./combined/41942.jpg: Very Poor (Label: 0.2905203402042389)\n",
      "./combined/42728.jpg: Very Poor (Label: 0.3061521649360657)\n",
      "./combined/18491.jpg: Very Poor (Label: 0.35707786679267883)\n",
      "./combined/59922.jpg: Very Poor (Label: 0.42358309030532837)\n",
      "./combined/43569.jpg: Very Poor (Label: 0.4284425973892212)\n",
      "./combined/12589.jpg: Very Poor (Label: 0.5228504538536072)\n",
      "./combined/17621.jpg: Very Poor (Label: 0.3643066883087158)\n",
      "./combined/2425.jpg: Very Poor (Label: 0.37293970584869385)\n",
      "./combined/47195.jpg: Very Poor (Label: 0.367032915353775)\n",
      "./combined/51807.jpg: Very Poor (Label: 0.5042336583137512)\n",
      "./combined/22996.jpg: Very Poor (Label: 0.27082496881484985)\n",
      "./combined/65908.jpg: Very Poor (Label: 0.5618503093719482)\n",
      "./combined/50715.jpg: Very Poor (Label: 0.4643021523952484)\n",
      "./combined/42378.jpg: Very Poor (Label: 0.38397905230522156)\n",
      "./combined/27628.jpg: Very Poor (Label: 0.387395977973938)\n",
      "./combined/35300.jpg: Very Poor (Label: 0.45453616976737976)\n",
      "./combined/28498.jpg: Very Poor (Label: 0.43735432624816895)\n",
      "./combined/63976.jpg: Very Poor (Label: 0.48291704058647156)\n",
      "./combined/67870.jpg: Very Poor (Label: 0.44461289048194885)\n",
      "./combined/49021.jpg: Very Poor (Label: 0.6227015852928162)\n",
      "./combined/2075.jpg: Very Poor (Label: 0.5206422209739685)\n",
      "./combined/2976.jpg: Very Poor (Label: 0.558523952960968)\n",
      "./combined/24004.jpg: Very Poor (Label: 0.5178447961807251)\n",
      "./combined/45002.jpg: Very Poor (Label: 0.39997902512550354)\n",
      "./combined/30801.jpg: Very Poor (Label: 0.2473345696926117)\n",
      "./combined/23684.jpg: Very Poor (Label: 0.3040282130241394)\n",
      "./combined/8497.jpg: Very Poor (Label: 0.4307411313056946)\n"
     ]
    }
   ],
   "source": [
    "for images, labels, img_paths in dataloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    output = model_predict_class(images, model)\n",
    "    for img_path, o, l in zip(img_paths, output, labels):\n",
    "        print(f\"{img_path}: {o} (Label: {l.item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
