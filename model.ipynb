{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SingleScoreCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleScoreCNN, self).__init__()\n",
    "        # Define the layers of the CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8)  # Adjust the size based on the input size\n",
    "        self.fc2 = nn.Linear(64 * 8, 64 * 2)  \n",
    "        self.fc3 = nn.Linear(64 * 2, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "model = SingleScoreCNN()\n",
    "output = model(torch.randn(1, 3, 64, 64))  # Example input tensor (batch_size, channels, height, width)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.MSELoss()  # For example, if it's a regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MeasuresDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None, indices=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        if indices is not None:\n",
    "            self.data = data.iloc[indices]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        page = str(int(self.data.iloc[idx]['Page']))\n",
    "        label = self.data.iloc[idx]['Final Score']\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, f\"{page}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float), img_path\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to the size expected by the network\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_file = \"measures_filtered.csv\"\n",
    "\n",
    "# Load dataset\n",
    "dataset = MeasuresDataset(csv_file=data_file, image_dir='./combined', transform=transform)\n",
    "\n",
    "# Splitting data indices for train and test\n",
    "total_size = len(dataset) // 2\n",
    "testsizepercent = 0.2\n",
    "test_size = int(testsizepercent * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "train_indices = indices[test_size:]\n",
    "test_indices = indices[:test_size]\n",
    "\n",
    "train_dataset = MeasuresDataset(csv_file=data_file, image_dir='./combined', transform=transform, indices=train_indices)\n",
    "test_dataset = MeasuresDataset(csv_file=data_file, image_dir='./combined', transform=transform, indices=test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Batch [100 / 820], MSE Loss: 0.0061\n",
      "Epoch [1/5], Batch [200 / 820], MSE Loss: 0.0043\n",
      "Epoch [1/5], Batch [300 / 820], MSE Loss: 0.0057\n",
      "Epoch [1/5], Batch [400 / 820], MSE Loss: 0.0055\n",
      "Epoch [1/5], Batch [500 / 820], MSE Loss: 0.0052\n",
      "Epoch [1/5], Batch [600 / 820], MSE Loss: 0.0025\n",
      "Epoch [1/5], Batch [700 / 820], MSE Loss: 0.0028\n",
      "Epoch [1/5], Batch [800 / 820], MSE Loss: 0.0053\n",
      "Epoch [1/5], MSE Loss: 0.0061\n",
      "Epoch [2/5], Batch [100 / 820], MSE Loss: 0.0049\n",
      "Epoch [2/5], Batch [200 / 820], MSE Loss: 0.0070\n",
      "Epoch [2/5], Batch [300 / 820], MSE Loss: 0.0034\n",
      "Epoch [2/5], Batch [400 / 820], MSE Loss: 0.0043\n",
      "Epoch [2/5], Batch [500 / 820], MSE Loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Prepare model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "device = \"mps\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batches = 0\n",
    "    for images, labels, img_paths in dataloader:\n",
    "        batches += 1\n",
    "        # Move data to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if batches % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batches} / {len(dataloader)}], MSE Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], MSE Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleScoreCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.6, 0.8, 1]\n",
    "def model_predict_class(image, model):\n",
    "    scores = model(image)\n",
    "    scores = scores.squeeze()\n",
    "    # print(scores)\n",
    "    categories, ss = [], []\n",
    "    for score in scores:\n",
    "        s = score.item()\n",
    "        # print(score)\n",
    "        if s <= 0.4:\n",
    "            category = \"Poor\"\n",
    "        elif 0.4 < s <= 0.6:\n",
    "            category = \"Fair\"\n",
    "        elif 0.6 < s <= 1:\n",
    "            category = \"Good\"\n",
    "        ss.append(s)\n",
    "        categories.append(category)\n",
    "    return categories, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./combined/30944.jpg: Fair (Predicted Score: 0.42467278242111206) (Label: 0.49458396434783936)\n",
      "./combined/58260.jpg: Fair (Predicted Score: 0.4145219326019287) (Label: 0.6077501177787781)\n",
      "./combined/3371.jpg: Fair (Predicted Score: 0.42681246995925903) (Label: 0.4156336188316345)\n",
      "./combined/34141.jpg: Fair (Predicted Score: 0.42437148094177246) (Label: 0.607175350189209)\n",
      "./combined/69478.jpg: Fair (Predicted Score: 0.43935713171958923) (Label: 0.40320464968681335)\n",
      "./combined/69497.jpg: Fair (Predicted Score: 0.4631856083869934) (Label: 0.47927504777908325)\n",
      "./combined/41807.jpg: Fair (Predicted Score: 0.4249987304210663) (Label: 0.26141196489334106)\n",
      "./combined/40715.jpg: Fair (Predicted Score: 0.48673486709594727) (Label: 0.46524909138679504)\n",
      "./combined/7277.jpg: Fair (Predicted Score: 0.42121148109436035) (Label: 0.38726162910461426)\n",
      "./combined/7762.jpg: Fair (Predicted Score: 0.4919270873069763) (Label: 0.47528767585754395)\n",
      "./combined/14518.jpg: Fair (Predicted Score: 0.44462668895721436) (Label: 0.37935277819633484)\n",
      "./combined/9286.jpg: Fair (Predicted Score: 0.482101172208786) (Label: 0.52044677734375)\n",
      "./combined/22580.jpg: Fair (Predicted Score: 0.40101906657218933) (Label: 0.39727693796157837)\n",
      "./combined/26193.jpg: Fair (Predicted Score: 0.4307745695114136) (Label: 0.2954588234424591)\n",
      "./combined/41554.jpg: Fair (Predicted Score: 0.42346489429473877) (Label: 0.29236501455307007)\n",
      "./combined/70659.jpg: Fair (Predicted Score: 0.41339683532714844) (Label: 0.5510207414627075)\n",
      "./combined/49021.jpg: Fair (Predicted Score: 0.46482202410697937) (Label: 0.6227015852928162)\n",
      "./combined/6870.jpg: Fair (Predicted Score: 0.4134313464164734) (Label: 0.25061851739883423)\n",
      "./combined/31343.jpg: Fair (Predicted Score: 0.4566296935081482) (Label: 0.35365062952041626)\n",
      "./combined/14148.jpg: Fair (Predicted Score: 0.4660763740539551) (Label: 0.5584520101547241)\n",
      "./combined/41041.jpg: Fair (Predicted Score: 0.4428171217441559) (Label: 0.5813817381858826)\n",
      "./combined/7298.jpg: Fair (Predicted Score: 0.440835177898407) (Label: 0.3645436763763428)\n",
      "./combined/29266.jpg: Poor (Predicted Score: 0.39784175157546997) (Label: 0.4741353690624237)\n",
      "./combined/17271.jpg: Fair (Predicted Score: 0.42036452889442444) (Label: 0.41383883357048035)\n",
      "./combined/31713.jpg: Fair (Predicted Score: 0.47779908776283264) (Label: 0.6047031879425049)\n",
      "./combined/8478.jpg: Fair (Predicted Score: 0.40176913142204285) (Label: 0.3767063617706299)\n",
      "./combined/67870.jpg: Poor (Predicted Score: 0.39614972472190857) (Label: 0.44461289048194885)\n",
      "./combined/6935.jpg: Fair (Predicted Score: 0.43016618490219116) (Label: 0.4186430871486664)\n",
      "./combined/1659.jpg: Fair (Predicted Score: 0.45972123742103577) (Label: 0.3446696400642395)\n",
      "./combined/38532.jpg: Fair (Predicted Score: 0.4840102791786194) (Label: 0.49811384081840515)\n",
      "./combined/40345.jpg: Fair (Predicted Score: 0.4504130482673645) (Label: 0.4429296553134918)\n",
      "./combined/18491.jpg: Poor (Predicted Score: 0.39769694209098816) (Label: 0.35707786679267883)\n",
      "./combined/52728.jpg: Fair (Predicted Score: 0.46286287903785706) (Label: 0.3075033724308014)\n",
      "./combined/56291.jpg: Fair (Predicted Score: 0.41547030210494995) (Label: 0.4747390151023865)\n",
      "./combined/36039.jpg: Fair (Predicted Score: 0.40392905473709106) (Label: 0.29003477096557617)\n",
      "./combined/22979.jpg: Poor (Predicted Score: 0.3995775878429413) (Label: 0.2504081130027771)\n",
      "./combined/62371.jpg: Fair (Predicted Score: 0.4112923741340637) (Label: 0.2946683168411255)\n",
      "./combined/21656.jpg: Fair (Predicted Score: 0.4783097803592682) (Label: 0.569007158279419)\n",
      "./combined/45002.jpg: Fair (Predicted Score: 0.4440683126449585) (Label: 0.39997902512550354)\n",
      "./combined/37297.jpg: Poor (Predicted Score: 0.39903032779693604) (Label: 0.3288934528827667)\n",
      "./combined/28498.jpg: Fair (Predicted Score: 0.43060657382011414) (Label: 0.43735432624816895)\n",
      "./combined/18868.jpg: Fair (Predicted Score: 0.4624699354171753) (Label: 0.48394104838371277)\n",
      "./combined/396.jpg: Fair (Predicted Score: 0.42183154821395874) (Label: 0.4373660087585449)\n",
      "./combined/37628.jpg: Fair (Predicted Score: 0.4262142777442932) (Label: 0.38117557764053345)\n",
      "./combined/35615.jpg: Fair (Predicted Score: 0.4095003604888916) (Label: 0.5123087763786316)\n",
      "./combined/49867.jpg: Fair (Predicted Score: 0.4018403887748718) (Label: 0.2963269054889679)\n",
      "./combined/39773.jpg: Fair (Predicted Score: 0.47611212730407715) (Label: 0.37263429164886475)\n",
      "./combined/2075.jpg: Fair (Predicted Score: 0.4947379231452942) (Label: 0.5206422209739685)\n",
      "./combined/43093.jpg: Fair (Predicted Score: 0.4002611041069031) (Label: 0.2917836308479309)\n",
      "./combined/63130.jpg: Fair (Predicted Score: 0.40338143706321716) (Label: 0.4186748266220093)\n",
      "./combined/26039.jpg: Fair (Predicted Score: 0.45482248067855835) (Label: 0.5631558299064636)\n",
      "./combined/40200.jpg: Poor (Predicted Score: 0.38528403639793396) (Label: 0.38450074195861816)\n",
      "./combined/29773.jpg: Fair (Predicted Score: 0.44782599806785583) (Label: 0.509272038936615)\n",
      "./combined/71418.jpg: Poor (Predicted Score: 0.3936995565891266) (Label: 0.2375715672969818)\n",
      "./combined/15759.jpg: Fair (Predicted Score: 0.4220921993255615) (Label: 0.3679032623767853)\n",
      "./combined/66298.jpg: Poor (Predicted Score: 0.3929708003997803) (Label: 0.3064066767692566)\n",
      "./combined/66277.jpg: Fair (Predicted Score: 0.44862496852874756) (Label: 0.25528356432914734)\n",
      "./combined/52378.jpg: Fair (Predicted Score: 0.4152999520301819) (Label: 0.8386437296867371)\n",
      "./combined/12423.jpg: Fair (Predicted Score: 0.443822979927063) (Label: 0.5169666409492493)\n",
      "./combined/55002.jpg: Fair (Predicted Score: 0.41033533215522766) (Label: 0.2905755043029785)\n",
      "./combined/25615.jpg: Fair (Predicted Score: 0.4696529507637024) (Label: 0.35217466950416565)\n",
      "./combined/62721.jpg: Fair (Predicted Score: 0.42943596839904785) (Label: 0.7032966017723083)\n",
      "./combined/39289.jpg: Fair (Predicted Score: 0.4200591742992401) (Label: 0.39807742834091187)\n",
      "./combined/35300.jpg: Fair (Predicted Score: 0.41264697909355164) (Label: 0.45453616976737976)\n",
      "./combined/68286.jpg: Fair (Predicted Score: 0.447200208902359) (Label: 0.35593438148498535)\n",
      "./combined/63560.jpg: Poor (Predicted Score: 0.3786408007144928) (Label: 0.1651800572872162)\n",
      "./combined/24907.jpg: Fair (Predicted Score: 0.42818355560302734) (Label: 0.41782814264297485)\n",
      "./combined/34511.jpg: Fair (Predicted Score: 0.48046016693115234) (Label: 0.6044862270355225)\n",
      "./combined/15309.jpg: Fair (Predicted Score: 0.4102470874786377) (Label: 0.23540830612182617)\n",
      "./combined/57896.jpg: Fair (Predicted Score: 0.41041967272758484) (Label: 0.47526833415031433)\n",
      "./combined/49888.jpg: Fair (Predicted Score: 0.41974323987960815) (Label: 0.37349289655685425)\n",
      "./combined/29289.jpg: Fair (Predicted Score: 0.4380694627761841) (Label: 0.4669857323169708)\n",
      "./combined/379.jpg: Poor (Predicted Score: 0.38393908739089966) (Label: 0.327903687953949)\n",
      "./combined/2425.jpg: Fair (Predicted Score: 0.4194750189781189) (Label: 0.37293970584869385)\n",
      "./combined/34907.jpg: Poor (Predicted Score: 0.3918183743953705) (Label: 0.360077828168869)\n",
      "./combined/6173.jpg: Fair (Predicted Score: 0.4079880714416504) (Label: 0.19082416594028473)\n",
      "./combined/2833.jpg: Poor (Predicted Score: 0.3932930827140808) (Label: 0.33796799182891846)\n",
      "./combined/39266.jpg: Poor (Predicted Score: 0.3980327546596527) (Label: 0.9663807153701782)\n",
      "./combined/46784.jpg: Fair (Predicted Score: 0.40545275807380676) (Label: 0.2843741774559021)\n",
      "./combined/54756.jpg: Fair (Predicted Score: 0.4642162322998047) (Label: 0.3390553295612335)\n",
      "./combined/62664.jpg: Fair (Predicted Score: 0.4044843316078186) (Label: 0.41546350717544556)\n",
      "./combined/35245.jpg: Fair (Predicted Score: 0.4212975800037384) (Label: 0.3996664583683014)\n",
      "./combined/41942.jpg: Fair (Predicted Score: 0.4110187590122223) (Label: 0.2905203402042389)\n",
      "./combined/3664.jpg: Poor (Predicted Score: 0.3842393755912781) (Label: 0.3258098065853119)\n",
      "./combined/23684.jpg: Fair (Predicted Score: 0.4315345883369446) (Label: 0.3040282130241394)\n",
      "./combined/20552.jpg: Fair (Predicted Score: 0.40862277150154114) (Label: 0.4411317706108093)\n",
      "./combined/8028.jpg: Fair (Predicted Score: 0.47166773676872253) (Label: 0.9633057713508606)\n",
      "./combined/48325.jpg: Fair (Predicted Score: 0.44583824276924133) (Label: 0.4072374999523163)\n",
      "./combined/51807.jpg: Fair (Predicted Score: 0.431094229221344) (Label: 0.5042336583137512)\n",
      "./combined/4908.jpg: Fair (Predicted Score: 0.41995126008987427) (Label: 0.3464964032173157)\n",
      "./combined/43586.jpg: Fair (Predicted Score: 0.44544947147369385) (Label: 0.512844443321228)\n",
      "./combined/28027.jpg: Fair (Predicted Score: 0.4167642593383789) (Label: 0.377508282661438)\n",
      "./combined/29636.jpg: Fair (Predicted Score: 0.4188172519207001) (Label: 0.5110117793083191)\n",
      "./combined/20047.jpg: Fair (Predicted Score: 0.4806993901729584) (Label: 0.24650150537490845)\n",
      "./combined/20801.jpg: Fair (Predicted Score: 0.4388394355773926) (Label: 0.43390798568725586)\n",
      "./combined/37278.jpg: Fair (Predicted Score: 0.4287028908729553) (Label: 0.5703657865524292)\n",
      "./combined/65908.jpg: Fair (Predicted Score: 0.40247616171836853) (Label: 0.5618503093719482)\n",
      "./combined/59867.jpg: Fair (Predicted Score: 0.4907197952270508) (Label: 0.4395882189273834)\n",
      "./combined/43569.jpg: Fair (Predicted Score: 0.40854835510253906) (Label: 0.4284425973892212)\n",
      "./combined/67173.jpg: Fair (Predicted Score: 0.45748502016067505) (Label: 0.44903764128685)\n",
      "./combined/51041.jpg: Fair (Predicted Score: 0.4360889792442322) (Label: 0.5281466245651245)\n",
      "./combined/67523.jpg: Poor (Predicted Score: 0.39067333936691284) (Label: 0.32912084460258484)\n",
      "./combined/42728.jpg: Poor (Predicted Score: 0.39294689893722534) (Label: 0.3061521649360657)\n",
      "./combined/20102.jpg: Fair (Predicted Score: 0.42342665791511536) (Label: 0.3419339060783386)\n",
      "./combined/48260.jpg: Fair (Predicted Score: 0.41352763772010803) (Label: 0.2774679362773895)\n",
      "./combined/71048.jpg: Fair (Predicted Score: 0.4655298590660095) (Label: 0.4083098769187927)\n",
      "./combined/2976.jpg: Fair (Predicted Score: 0.44232097268104553) (Label: 0.558523952960968)\n",
      "./combined/39636.jpg: Fair (Predicted Score: 0.413400799036026) (Label: 0.2961859107017517)\n",
      "./combined/2999.jpg: Fair (Predicted Score: 0.4680418074131012) (Label: 0.4621296525001526)\n",
      "./combined/50345.jpg: Poor (Predicted Score: 0.38943594694137573) (Label: 0.30090901255607605)\n",
      "./combined/33391.jpg: Fair (Predicted Score: 0.4268476963043213) (Label: 0.4310688078403473)\n",
      "./combined/67466.jpg: Fair (Predicted Score: 0.4576859176158905) (Label: 0.4444652199745178)\n",
      "./combined/60209.jpg: Fair (Predicted Score: 0.40079087018966675) (Label: 0.43110188841819763)\n",
      "./combined/41411.jpg: Fair (Predicted Score: 0.4190062880516052) (Label: 0.26348698139190674)\n",
      "./combined/66627.jpg: Fair (Predicted Score: 0.40896132588386536) (Label: 0.43304282426834106)\n",
      "./combined/30047.jpg: Poor (Predicted Score: 0.39416027069091797) (Label: 0.46881937980651855)\n",
      "./combined/49922.jpg: Fair (Predicted Score: 0.44858628511428833) (Label: 0.20880739390850067)\n",
      "./combined/30801.jpg: Fair (Predicted Score: 0.444789320230484) (Label: 0.2473345696926117)\n",
      "./combined/54613.jpg: Fair (Predicted Score: 0.4588282108306885) (Label: 0.3809809386730194)\n",
      "./combined/34004.jpg: Fair (Predicted Score: 0.45576679706573486) (Label: 0.4421515166759491)\n",
      "./combined/51104.jpg: Fair (Predicted Score: 0.4688275456428528) (Label: 0.5346242785453796)\n",
      "./combined/24141.jpg: Poor (Predicted Score: 0.39924243092536926) (Label: 0.3105893135070801)\n",
      "./combined/57480.jpg: Fair (Predicted Score: 0.46870172023773193) (Label: 0.45537540316581726)\n",
      "./combined/59471.jpg: Fair (Predicted Score: 0.4298264980316162) (Label: 0.3103591203689575)\n",
      "./combined/8182.jpg: Fair (Predicted Score: 0.4183042049407959) (Label: 0.42574334144592285)\n",
      "./combined/18887.jpg: Fair (Predicted Score: 0.43082162737846375) (Label: 0.27527284622192383)\n",
      "./combined/46291.jpg: Fair (Predicted Score: 0.4055854082107544) (Label: 0.29815101623535156)\n",
      "./combined/28861.jpg: Fair (Predicted Score: 0.46808868646621704) (Label: 0.49558672308921814)\n",
      "./combined/13398.jpg: Fair (Predicted Score: 0.45246031880378723) (Label: 0.31311550736427307)\n",
      "./combined/7332.jpg: Fair (Predicted Score: 0.51670902967453) (Label: 0.5334049463272095)\n",
      "./combined/38162.jpg: Fair (Predicted Score: 0.4024938941001892) (Label: 0.4492754638195038)\n",
      "./combined/44756.jpg: Fair (Predicted Score: 0.43931490182876587) (Label: 0.46571582555770874)\n",
      "./combined/9793.jpg: Fair (Predicted Score: 0.42335081100463867) (Label: 0.38348791003227234)\n",
      "./combined/24004.jpg: Fair (Predicted Score: 0.4321907162666321) (Label: 0.5178447961807251)\n",
      "./combined/47896.jpg: Fair (Predicted Score: 0.4450870454311371) (Label: 0.4865572154521942)\n",
      "./combined/27628.jpg: Fair (Predicted Score: 0.4357013702392578) (Label: 0.387395977973938)\n",
      "./combined/36486.jpg: Poor (Predicted Score: 0.3915933668613434) (Label: 0.26150739192962646)\n",
      "./combined/63833.jpg: Fair (Predicted Score: 0.4228018522262573) (Label: 0.3038257360458374)\n",
      "./combined/17764.jpg: Fair (Predicted Score: 0.4229819178581238) (Label: 0.22572214901447296)\n",
      "./combined/42397.jpg: Poor (Predicted Score: 0.3856194317340851) (Label: 0.3718714714050293)\n",
      "./combined/47195.jpg: Fair (Predicted Score: 0.4277750253677368) (Label: 0.367032915353775)\n",
      "./combined/16460.jpg: Fair (Predicted Score: 0.4435044825077057) (Label: 0.8050859570503235)\n",
      "./combined/42378.jpg: Fair (Predicted Score: 0.43425193428993225) (Label: 0.38397905230522156)\n",
      "./combined/61048.jpg: Fair (Predicted Score: 0.46418893337249756) (Label: 0.30962228775024414)\n",
      "./combined/47879.jpg: Fair (Predicted Score: 0.454277366399765) (Label: 0.44660162925720215)\n",
      "./combined/32580.jpg: Fair (Predicted Score: 0.4331362247467041) (Label: 0.3903859555721283)\n",
      "./combined/32996.jpg: Fair (Predicted Score: 0.4211077094078064) (Label: 0.36430904269218445)\n",
      "./combined/41104.jpg: Fair (Predicted Score: 0.43882566690444946) (Label: 0.4479947090148926)\n",
      "./combined/50715.jpg: Fair (Predicted Score: 0.40610551834106445) (Label: 0.4643021523952484)\n",
      "./combined/30552.jpg: Fair (Predicted Score: 0.4381694495677948) (Label: 0.4893557131290436)\n",
      "./combined/55517.jpg: Poor (Predicted Score: 0.3918634057044983) (Label: 0.3409286439418793)\n",
      "./combined/38861.jpg: Poor (Predicted Score: 0.39212000370025635) (Label: 0.27792832255363464)\n",
      "./combined/53569.jpg: Fair (Predicted Score: 0.4439738392829895) (Label: 0.5378979444503784)\n",
      "./combined/50200.jpg: Fair (Predicted Score: 0.40514111518859863) (Label: 0.42420998215675354)\n",
      "./combined/56784.jpg: Fair (Predicted Score: 0.43475833535194397) (Label: 0.6516651511192322)\n",
      "./combined/44243.jpg: Fair (Predicted Score: 0.47099196910858154) (Label: 0.4100388288497925)\n",
      "./combined/45844.jpg: Fair (Predicted Score: 0.4485706388950348) (Label: 0.4149131178855896)\n",
      "./combined/27782.jpg: Fair (Predicted Score: 0.4266926944255829) (Label: 0.42889007925987244)\n",
      "./combined/48775.jpg: Fair (Predicted Score: 0.45924851298332214) (Label: 0.25704464316368103)\n",
      "./combined/32095.jpg: Poor (Predicted Score: 0.3822205066680908) (Label: 0.33085504174232483)\n",
      "./combined/39323.jpg: Fair (Predicted Score: 0.424999475479126) (Label: 0.45409321784973145)\n",
      "./combined/31206.jpg: Fair (Predicted Score: 0.43706682324409485) (Label: 0.4973643720149994)\n",
      "./combined/22095.jpg: Fair (Predicted Score: 0.4699023365974426) (Label: 0.40861770510673523)\n",
      "./combined/49534.jpg: Fair (Predicted Score: 0.4182819724082947) (Label: 0.4235350489616394)\n",
      "./combined/28477.jpg: Fair (Predicted Score: 0.4361616373062134) (Label: 0.43710628151893616)\n",
      "./combined/67036.jpg: Fair (Predicted Score: 0.4101800322532654) (Label: 0.4256013035774231)\n",
      "./combined/26486.jpg: Fair (Predicted Score: 0.43401899933815) (Label: 0.4913545548915863)\n",
      "./combined/49164.jpg: Fair (Predicted Score: 0.4364582300186157) (Label: 0.3618248999118805)\n",
      "./combined/33684.jpg: Poor (Predicted Score: 0.39478737115859985) (Label: 0.33088418841362)\n",
      "./combined/63976.jpg: Fair (Predicted Score: 0.44713786244392395) (Label: 0.48291704058647156)\n",
      "./combined/32979.jpg: Fair (Predicted Score: 0.46943336725234985) (Label: 0.34706804156303406)\n",
      "./combined/45517.jpg: Fair (Predicted Score: 0.43461698293685913) (Label: 0.6205604076385498)\n",
      "./combined/26890.jpg: Fair (Predicted Score: 0.461731880903244) (Label: 0.36296582221984863)\n",
      "./combined/17621.jpg: Poor (Predicted Score: 0.3911059498786926) (Label: 0.3643066883087158)\n",
      "./combined/6036.jpg: Fair (Predicted Score: 0.4320310950279236) (Label: 0.2509579360485077)\n",
      "./combined/13727.jpg: Fair (Predicted Score: 0.4235934615135193) (Label: 0.5058339238166809)\n",
      "./combined/48630.jpg: Fair (Predicted Score: 0.4167347550392151) (Label: 0.37909746170043945)\n",
      "./combined/30417.jpg: Fair (Predicted Score: 0.4400763511657715) (Label: 0.3350168466567993)\n",
      "./combined/50650.jpg: Fair (Predicted Score: 0.49960047006607056) (Label: 0.4494112432003021)\n",
      "./combined/28532.jpg: Poor (Predicted Score: 0.38903889060020447) (Label: 0.2036718875169754)\n",
      "./combined/16876.jpg: Fair (Predicted Score: 0.45994555950164795) (Label: 0.3944268524646759)\n",
      "./combined/16175.jpg: Fair (Predicted Score: 0.4428405165672302) (Label: 0.2640734314918518)\n",
      "./combined/28162.jpg: Fair (Predicted Score: 0.4272584021091461) (Label: 0.41489821672439575)\n",
      "./combined/53139.jpg: Fair (Predicted Score: 0.4089752435684204) (Label: 0.3236065208911896)\n",
      "./combined/13662.jpg: Fair (Predicted Score: 0.4348541498184204) (Label: 0.37256836891174316)\n",
      "./combined/54243.jpg: Fair (Predicted Score: 0.4518851637840271) (Label: 0.26034247875213623)\n",
      "./combined/6523.jpg: Fair (Predicted Score: 0.4576023519039154) (Label: 0.25869226455688477)\n",
      "./combined/60659.jpg: Fair (Predicted Score: 0.48617804050445557) (Label: 0.5829766392707825)\n",
      "./combined/58775.jpg: Fair (Predicted Score: 0.40165913105010986) (Label: 0.6192781329154968)\n",
      "./combined/63999.jpg: Fair (Predicted Score: 0.4440460205078125) (Label: 0.5053449273109436)\n",
      "./combined/59922.jpg: Fair (Predicted Score: 0.4336325526237488) (Label: 0.42358309030532837)\n",
      "./combined/20944.jpg: Fair (Predicted Score: 0.4079079031944275) (Label: 0.370860755443573)\n",
      "./combined/66332.jpg: Fair (Predicted Score: 0.4099080562591553) (Label: 0.469314306974411)\n",
      "./combined/34842.jpg: Fair (Predicted Score: 0.40781235694885254) (Label: 0.5367657542228699)\n",
      "./combined/69028.jpg: Poor (Predicted Score: 0.3718782663345337) (Label: 0.23834392428398132)\n",
      "./combined/68793.jpg: Fair (Predicted Score: 0.45503073930740356) (Label: 0.5135580897331238)\n",
      "./combined/25300.jpg: Fair (Predicted Score: 0.42539459466934204) (Label: 0.26404449343681335)\n",
      "./combined/30102.jpg: Fair (Predicted Score: 0.4052935838699341) (Label: 0.3468853533267975)\n",
      "./combined/66762.jpg: Fair (Predicted Score: 0.43126794695854187) (Label: 0.3984478712081909)\n",
      "./combined/24842.jpg: Fair (Predicted Score: 0.4677269756793976) (Label: 0.6243467926979065)\n",
      "./combined/63425.jpg: Poor (Predicted Score: 0.3979629874229431) (Label: 0.353488028049469)\n",
      "./combined/59888.jpg: Fair (Predicted Score: 0.42442432045936584) (Label: 0.37280356884002686)\n"
     ]
    }
   ],
   "source": [
    "for images, labels, img_paths in dataloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    output, scores = model_predict_class(images, model)\n",
    "    for img_path, o, l, s  in zip(img_paths, output, labels, scores):\n",
    "        print(f\"{img_path}: {o} (Predicted Score: {s}) (Label: {l.item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|█████████▉| 414/415 [02:51<00:00,  2.41it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels, img_paths \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing Images\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     54\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 55\u001b[0m     output, scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_predict_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Append true labels and predicted labels from each batch\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     true_labels\u001b[38;5;241m.\u001b[39mextend([get_category(label\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels])\n",
      "Cell \u001b[0;32mIn[21], line 19\u001b[0m, in \u001b[0;36mmodel_predict_class\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     18\u001b[0m categories, ss \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores:\n\u001b[1;32m     20\u001b[0m     s \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1022\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1022\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m   1024\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1025\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1026\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1031\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_category(label):\n",
    "    if s <= 0.4:\n",
    "        return \"Poor\"\n",
    "    elif 0.4 < s <= 0.6:\n",
    "        return \"Fair\"\n",
    "    elif 0.6 < s <= 1:\n",
    "        return \"Good\"\n",
    "\n",
    "def model_predict_class(image, model):\n",
    "    scores = model(image)\n",
    "    scores = scores.squeeze()\n",
    "    categories, ss = [], []\n",
    "    for score in scores:\n",
    "        s = score.item()\n",
    "        if s <= 0.4:\n",
    "            category = \"Poor\"\n",
    "        elif 0.4 < s <= 0.6:\n",
    "            category = \"Fair\"\n",
    "        elif 0.6 < s <= 1:\n",
    "            category = \"Good\"\n",
    "        ss.append(s)\n",
    "        categories.append(category)\n",
    "    return categories, ss\n",
    "\n",
    "def create_confusion_matrix(labels, predictions):\n",
    "    categories = [\"Poor\", \"Fair\", \"Good\"]\n",
    "    confusion_matrix = np.zeros((len(categories), len(categories)), dtype=int)\n",
    "    for i in range(len(labels)):\n",
    "        true_category = labels[i]\n",
    "        pred_category = predictions[i]\n",
    "        true_index = categories.index(true_category)\n",
    "        pred_index = categories.index(pred_category)\n",
    "        confusion_matrix[true_index][pred_index] += 1\n",
    "    return confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize lists to store labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through test_loader with tqdm for progress tracking\n",
    "for images, labels, img_paths in tqdm(test_loader, desc='Processing Images'):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    output, scores = model_predict_class(images, model)\n",
    "    # Append true labels and predicted labels from each batch\n",
    "    true_labels.extend([get_category(label.item()) for label in labels])\n",
    "    predicted_labels.extend(output)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = create_confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0   32   54    0    0]\n",
      " [   0  261  904    0    0]\n",
      " [   0 1669 8504    0    0]\n",
      " [   0  166 1646    0    0]\n",
      " [   0    0   12    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = create_confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.15851806863042817, 0.7987601559197858, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_f1_scores(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    f1_scores = []\n",
    "\n",
    "    # Calculating precision, recall, and F1 score for each class\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]\n",
    "        FP = np.sum(conf_matrix[:, i]) - TP\n",
    "        FN = np.sum(conf_matrix[i, :]) - TP\n",
    "        \n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return f1_scores\n",
    "\n",
    "calculate_f1_scores(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
