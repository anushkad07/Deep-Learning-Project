{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SingleScoreCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleScoreCNN, self).__init__()\n",
    "        # Define the layers of the CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8)  # Adjust the size based on the input size\n",
    "        self.fc2 = nn.Linear(64 * 8, 64 * 2)  \n",
    "        self.fc3 = nn.Linear(64 * 2, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "model = SingleScoreCNN()\n",
    "output = model(torch.randn(1, 3, 64, 64))  # Example input tensor (batch_size, channels, height, width)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.MSELoss()  # For example, if it's a regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MeasuresDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        page = str(int(self.data.iloc[idx]['Page']))\n",
    "        label = self.data.iloc[idx]['Final Score']\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, f\"{page}.jpg\")\n",
    "        # print(page, label, img_path)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformations, if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to the size expected by the network\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = MeasuresDataset(csv_file='measures.csv', image_dir='./combined', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate over the dataloader\n",
    "# for images, labels in dataloader:\n",
    "#     # Feed data to the model\n",
    "#     output = model(images)\n",
    "#     # Compute the loss, etc.\n",
    "#     print(output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], MSE Loss: 53.6609\n",
      "Epoch [2/20], MSE Loss: 20.8431\n",
      "Epoch [3/20], MSE Loss: 20.8554\n",
      "Epoch [4/20], MSE Loss: 25.1069\n",
      "Epoch [5/20], MSE Loss: 22.7182\n",
      "Epoch [6/20], MSE Loss: 22.7317\n",
      "Epoch [7/20], MSE Loss: 55.7281\n",
      "Epoch [8/20], MSE Loss: 22.6700\n",
      "Epoch [9/20], MSE Loss: 23.0560\n",
      "Epoch [10/20], MSE Loss: 22.6022\n",
      "Epoch [11/20], MSE Loss: 30.1395\n",
      "Epoch [12/20], MSE Loss: 22.7785\n",
      "Epoch [13/20], MSE Loss: 22.4270\n",
      "Epoch [14/20], MSE Loss: 34.8570\n",
      "Epoch [15/20], MSE Loss: 21.2060\n",
      "Epoch [16/20], MSE Loss: 21.0018\n",
      "Epoch [17/20], MSE Loss: 22.9360\n",
      "Epoch [18/20], MSE Loss: 20.8294\n",
      "Epoch [19/20], MSE Loss: 22.7023\n",
      "Epoch [20/20], MSE Loss: 22.4042\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Prepare model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        # Move data to GPU if available\n",
    "        # images, labels = images.cuda(), labels.cuda() if torch.cuda.is_available() else (images, labels)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], MSE Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
