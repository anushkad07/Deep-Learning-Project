{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Dataset class to load data\n",
    "class MeasuresDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        page = str(int(self.data.iloc[idx]['Page']))\n",
    "        label = self.data.iloc[idx]['Final Score']\n",
    "        text_description = self.data.iloc[idx]['Description']\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, f\"{page}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        text_description = clip.tokenize([text_description]).squeeze(0)\n",
    "\n",
    "        return image, text_description, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "# Preprocessing and dataset loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = MeasuresDataset(csv_file='measures_context.csv', image_dir='./combined', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(predicted_score, target_score):\n",
    "    return torch.exp(-torch.abs(predicted_score - target_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFlowNetAgent(nn.Module):\n",
    "    def __init__(self, clip_model):\n",
    "        super(GFlowNetAgent, self).__init__()\n",
    "        self.clip_model = clip_model\n",
    "        self.fc = nn.Linear(clip_model.visual.output_dim * 2, 3*224*224)\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        with torch.no_grad():\n",
    "            image_features = self.clip_model.encode_image(image)\n",
    "            text_features = self.clip_model.encode_text(text)\n",
    "\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        print(combined_features.shape)\n",
    "        action = self.fc(combined_features)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gflownet(agent, optimizer, dataloader, model, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        agent.train()\n",
    "        epoch_loss = 0\n",
    "        for images, texts, labels in dataloader:\n",
    "            images, texts, labels = images.to(device), texts.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            action = agent(images, texts)\n",
    "            print(action.shape)\n",
    "            generated_image = images + action.view(images.shape)\n",
    "            \n",
    "            predicted_score = model(generated_image, texts)\n",
    "            reward = reward_function(predicted_score.squeeze(), labels)\n",
    "            \n",
    "            loss = -reward.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], GFlowNet Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_gflownet(agent, text, target_score, num_steps=10):\n",
    "    state = torch.randn(1, 3, 224, 224).to(device)\n",
    "    text = clip.tokenize([text]).to(device)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        action = agent(state, text)\n",
    "        state += action.view(state.shape)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024])\n",
      "torch.Size([32, 150528])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(agent\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the GFlowNet model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain_gflownet\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Generate an image for a specific target score\u001b[39;00m\n\u001b[1;32m     13\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn image description.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[26], line 14\u001b[0m, in \u001b[0;36mtrain_gflownet\u001b[0;34m(agent, optimizer, dataloader, model, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(action\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m images \u001b[38;5;241m+\u001b[39m action\u001b[38;5;241m.\u001b[39mview(images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 14\u001b[0m predicted_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m reward \u001b[38;5;241m=\u001b[39m reward_function(predicted_score\u001b[38;5;241m.\u001b[39msqueeze(), labels)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mreward\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\")\n",
    "clip_model = clip_model.to(device)\n",
    "\n",
    "# Initialize agent and optimizer\n",
    "agent = GFlowNetAgent(clip_model).to(device)\n",
    "optimizer = optim.Adam(agent.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the GFlowNet model\n",
    "train_gflownet(agent, optimizer, dataloader, model=None, num_epochs=5)\n",
    "\n",
    "# Generate an image for a specific target score\n",
    "description = \"An image description.\"\n",
    "target_score = 0.7\n",
    "generated_image = generate_image_gflownet(agent, description, target_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
